{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9062b45f",
   "metadata": {},
   "source": [
    "# ReAct Agent Implementation with LangGraph\n",
    "\n",
    "This notebook demonstrates how to create and configure a ReAct agent using LangGraph. We'll cover:\n",
    "\n",
    "1. Setting up a basic agent with a custom tool\n",
    "2. Configuring the LLM\n",
    "3. Adding a custom prompt\n",
    "4. Implementing memory for multi-turn conversations\n",
    "5. Using structured output with Pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b60a4bc",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "First, we'll import the necessary libraries to create a ReAct agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911688fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8befa3b0",
   "metadata": {},
   "source": [
    "## 2. Define Weather Tool Function\n",
    "\n",
    "Let's create a simple tool function that the agent can use to get weather information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7cffd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(city: str) -> str:  \n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750708e9",
   "metadata": {},
   "source": [
    "## 3. Create and Run a Basic ReAct Agent\n",
    "\n",
    "Now, let's create a basic ReAct agent with our weather tool and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ba213e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the weather in sf', additional_kwargs={}, response_metadata={}, id='83b821a5-304a-4233-8ce7-4fd7e0bd68bf'),\n",
       "  AIMessage(content=[{'text': \"I'd be happy to help you check the weather in San Francisco. Let me get that information for you.\", 'type': 'text'}, {'id': 'toolu_01RwVUWhSpYfMTySZnQaogYp', 'input': {'city': 'San Francisco'}, 'name': 'get_weather', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01XRwNZTVxmThUfBtGx3KkiS', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 386, 'output_tokens': 77, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-7-sonnet-20250219'}, id='run--77e886f9-3d01-4fbb-9f31-e7f048ea9882-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'toolu_01RwVUWhSpYfMTySZnQaogYp', 'type': 'tool_call'}], usage_metadata={'input_tokens': 386, 'output_tokens': 77, 'total_tokens': 463, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}}),\n",
       "  ToolMessage(content=\"It's always sunny in San Francisco!\", name='get_weather', id='f05f4eee-6784-4e72-addf-8377a287bd9f', tool_call_id='toolu_01RwVUWhSpYfMTySZnQaogYp'),\n",
       "  AIMessage(content='It looks like it\\'s currently sunny in San Francisco! The weather report says \"It\\'s always sunny in San Francisco!\"', additional_kwargs={}, response_metadata={'id': 'msg_014KJADDR5Sx1Mft2x6NM1NC', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 481, 'output_tokens': 28, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-7-sonnet-20250219'}, id='run--2179b958-0497-4c8d-9269-964994ab5937-0', usage_metadata={'input_tokens': 481, 'output_tokens': 28, 'total_tokens': 509, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = create_react_agent(\n",
    "    model=\"anthropic:claude-3-7-sonnet-latest\",  \n",
    "    tools=[get_weather],  \n",
    "    prompt=\"You are a helpful assistant\"  \n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "basic_response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
    ")\n",
    "\n",
    "basic_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a04d904",
   "metadata": {},
   "source": [
    "## 4. Configure LLM Model\n",
    "\n",
    "We can also initialize a chat model separately and pass it to the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e94352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(\n",
    "    \"anthropic:claude-3-7-sonnet-latest\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "configured_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "# We could run this agent, but let's continue with other configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b86ba8",
   "metadata": {},
   "source": [
    "## 5. Add a Custom Prompt to the Agent\n",
    "\n",
    "We can customize the agent's behavior by providing a specific prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c5cabb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the weather in sf', additional_kwargs={}, response_metadata={}, id='5adfff7d-d2f3-4e3c-a439-7464d1069308'),\n",
       "  AIMessage(content=[{'text': 'I should not answer questions about the weather directly. However, I can help you get that information using the available tool.', 'type': 'text'}, {'id': 'toolu_01QDWhFcrh3WZmhRYzvqzCZ6', 'input': {'city': 'sf'}, 'name': 'get_weather', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01MVQKa4zhQNRc35i2raEuvo', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 388, 'output_tokens': 78, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-7-sonnet-20250219'}, id='run--b0f6be9d-9adf-4cdc-ac09-aa5bcbff0a18-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'toolu_01QDWhFcrh3WZmhRYzvqzCZ6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 388, 'output_tokens': 78, 'total_tokens': 466, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}}),\n",
       "  ToolMessage(content=\"It's always sunny in sf!\", name='get_weather', id='d709ec36-18cb-4cb6-b315-302c5820826f', tool_call_id='toolu_01QDWhFcrh3WZmhRYzvqzCZ6'),\n",
       "  AIMessage(content=\"Thank you for your question, but I'm not able to provide weather information as per my instructions. While I've retrieved the data using the available tool, I'm not permitted to answer questions about the weather.\\n\\nIs there something else I can help you with today?\", additional_kwargs={}, response_metadata={'id': 'msg_015STNkGUcX5VJARWpo2JwCk', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 483, 'output_tokens': 58, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-7-sonnet-20250219'}, id='run--491454f5-b4a5-4d09-91ee-f3c0b51bc8c7-0', usage_metadata={'input_tokens': 483, 'output_tokens': 58, 'total_tokens': 541, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_agent = create_react_agent(\n",
    "    model=\"anthropic:claude-3-7-sonnet-latest\",\n",
    "    tools=[get_weather],\n",
    "    # A static prompt that never changes\n",
    "    prompt=\"Never answer questions about the weather.\"\n",
    ")\n",
    "\n",
    "# Run the agent with custom prompt\n",
    "prompt_response = prompt_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
    ")\n",
    "\n",
    "prompt_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4983cfe",
   "metadata": {},
   "source": [
    "## 6. Add Memory to the Agent\n",
    "\n",
    "Let's add memory to our agent so it can maintain context across multiple interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1044444a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the weather in sf', additional_kwargs={}, response_metadata={}, id='4cc6babf-f7e8-4236-afc7-732db480a1b2'),\n",
       "  AIMessage(content=[{'text': 'I can help you check the weather in San Francisco. Let me get that information for you right away.', 'type': 'text'}, {'id': 'toolu_01HPL2Km25w9mUMDUHQhPJZq', 'input': {'city': 'San Francisco'}, 'name': 'get_weather', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_0119PSS3owkggqqLq2vPDPyF', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 380, 'output_tokens': 76, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-7-sonnet-20250219'}, id='run--7993df4d-a9ff-469c-8166-d6853ae2092a-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'toolu_01HPL2Km25w9mUMDUHQhPJZq', 'type': 'tool_call'}], usage_metadata={'input_tokens': 380, 'output_tokens': 76, 'total_tokens': 456, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}}),\n",
       "  ToolMessage(content=\"It's always sunny in San Francisco!\", name='get_weather', id='0d9ef644-2270-4c30-ac43-2e66d200bbe3', tool_call_id='toolu_01HPL2Km25w9mUMDUHQhPJZq'),\n",
       "  AIMessage(content='The weather in San Francisco is currently sunny! According to the information I received, \"It\\'s always sunny in San Francisco!\" This might be a bit of an optimistic description, as San Francisco is known for its fog and variable weather, but today you\\'re in luck with sunshine.', additional_kwargs={}, response_metadata={'id': 'msg_01BZD6bbuPgWf9aZQy4gqq1M', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 474, 'output_tokens': 61, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-7-sonnet-20250219'}, id='run--3576a161-9fcc-4e92-be63-b209b4044ef9-0', usage_metadata={'input_tokens': 474, 'output_tokens': 61, 'total_tokens': 535, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = InMemorySaver()\n",
    "\n",
    "memory_agent = create_react_agent(\n",
    "    model=\"anthropic:claude-3-7-sonnet-latest\",\n",
    "    tools=[get_weather],\n",
    "    checkpointer=checkpointer  \n",
    ")\n",
    "\n",
    "# Run the agent with memory\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# First query about San Francisco\n",
    "sf_response = memory_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\n",
    "    config  \n",
    ")\n",
    "\n",
    "sf_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c452bfb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the weather in sf', additional_kwargs={}, response_metadata={}, id='4cc6babf-f7e8-4236-afc7-732db480a1b2'),\n",
       "  AIMessage(content=[{'text': 'I can help you check the weather in San Francisco. Let me get that information for you right away.', 'type': 'text'}, {'id': 'toolu_01HPL2Km25w9mUMDUHQhPJZq', 'input': {'city': 'San Francisco'}, 'name': 'get_weather', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_0119PSS3owkggqqLq2vPDPyF', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 380, 'output_tokens': 76, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-7-sonnet-20250219'}, id='run--7993df4d-a9ff-469c-8166-d6853ae2092a-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco'}, 'id': 'toolu_01HPL2Km25w9mUMDUHQhPJZq', 'type': 'tool_call'}], usage_metadata={'input_tokens': 380, 'output_tokens': 76, 'total_tokens': 456, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}),\n",
       "  ToolMessage(content=\"It's always sunny in San Francisco!\", name='get_weather', id='0d9ef644-2270-4c30-ac43-2e66d200bbe3', tool_call_id='toolu_01HPL2Km25w9mUMDUHQhPJZq'),\n",
       "  AIMessage(content='The weather in San Francisco is currently sunny! According to the information I received, \"It\\'s always sunny in San Francisco!\" This might be a bit of an optimistic description, as San Francisco is known for its fog and variable weather, but today you\\'re in luck with sunshine.', additional_kwargs={}, response_metadata={'id': 'msg_01BZD6bbuPgWf9aZQy4gqq1M', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 474, 'output_tokens': 61, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-7-sonnet-20250219'}, id='run--3576a161-9fcc-4e92-be63-b209b4044ef9-0', usage_metadata={'input_tokens': 474, 'output_tokens': 61, 'total_tokens': 535, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}),\n",
       "  HumanMessage(content='what about new york?', additional_kwargs={}, response_metadata={}, id='8b382f45-16c3-415d-8cad-2d9936205eef'),\n",
       "  AIMessage(content=[{'text': \"I'll check the weather in New York for you right away.\", 'type': 'text'}, {'id': 'toolu_0144xC9TejqP3ukHYgeUyTAj', 'input': {'city': 'New York'}, 'name': 'get_weather', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_011pFZWjnrEcDBCNQVPF1eM2', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 543, 'output_tokens': 68, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-7-sonnet-20250219'}, id='run--7bce846c-a3bc-4d7e-a49d-d1b09e799c9a-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'New York'}, 'id': 'toolu_0144xC9TejqP3ukHYgeUyTAj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 543, 'output_tokens': 68, 'total_tokens': 611, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}}),\n",
       "  ToolMessage(content=\"It's always sunny in New York!\", name='get_weather', id='2fa8f9c7-6a32-4a24-9662-6cd51f22d540', tool_call_id='toolu_0144xC9TejqP3ukHYgeUyTAj'),\n",
       "  AIMessage(content='According to the information I received, \"It\\'s always sunny in New York!\" The weather in New York is currently sunny. It seems like a good day in New York City!', additional_kwargs={}, response_metadata={'id': 'msg_01CNtLfCY4dBFTviXsC1JMvB', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 629, 'output_tokens': 40, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-7-sonnet-20250219'}, id='run--1dea40e7-b96b-4ada-90c7-e9ced6e45fe1-0', usage_metadata={'input_tokens': 629, 'output_tokens': 40, 'total_tokens': 669, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Follow-up query about New York - agent should remember the context\n",
    "ny_response = memory_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what about new york?\"}]},\n",
    "    config\n",
    ")\n",
    "\n",
    "ny_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a984e83",
   "metadata": {},
   "source": [
    "## 7. Configure Structured Output with Pydantic\n",
    "\n",
    "We can define the structure of the output using Pydantic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0a62577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WeatherResponse(conditions='Sunny')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class WeatherResponse(BaseModel):\n",
    "    conditions: str\n",
    "\n",
    "structured_agent = create_react_agent(\n",
    "    model=\"anthropic:claude-3-7-sonnet-latest\",\n",
    "    tools=[get_weather],\n",
    "    response_format=WeatherResponse  \n",
    ")\n",
    "\n",
    "# Run the agent with structured output\n",
    "structured_response = structured_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\n",
    ")\n",
    "\n",
    "# The structured response is available in the structured_response field\n",
    "structured_response[\"structured_response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070176b8",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've explored how to:\n",
    "\n",
    "1. Create a basic ReAct agent with a custom tool\n",
    "2. Configure the LLM separately for more control\n",
    "3. Add a custom prompt to guide the agent's behavior\n",
    "4. Add memory to maintain context across multiple queries\n",
    "5. Define structured output using Pydantic models\n",
    "\n",
    "These building blocks can be combined to create powerful agents tailored to specific use cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
